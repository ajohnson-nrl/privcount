#!/usr/bin/env python

import datetime
import os
import sys

from multiprocessing import Pool, cpu_count
from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter

from numpy import mean
from stem import Flag
from stem.descriptor import parse_file
from stem.descriptor import DocumentHandler
from stem.descriptor.remote import DescriptorDownloader
from stem.version import Version

def get_unknown_privcount_version_stub():
    return 'unknown (>= PrivCount 1.0.1)'

try:
    from privcount.protocol import get_privcount_version
except:
    get_privcount_version = get_unknown_privcount_version_stub

'''
This is a general purpose tool that will search through a consenus or all
consensuses in a directory and compute the mean position weights that a
group of relays by fingerprints had over all consensuses.

Clients typically have a consensus that is between 1 and 3 hours old. You
should choose a range of consensuses that reflect this delay. (For example, if
you collect between 03:00 and 23:00, use consensuses 01:00 through 20:00.)

HSDir v2s rotate every 24 hours at a time based on each service's onion
address. To avoid introducing bias, you MUST collect v2 HSDir statistics for
a multiple of  24 hours.

HSDir v2s see one more set of descriptors than the number of days in the
collection period, because the changeovers are distributed throughout the
day. Therefore, any figures obtained from an N-day period need to be scaled by
N/(N+1).

This script provides simplified weights, which don't account for:
* exit ports, exit policies, and exit and rend long-lived ports
* HSDir v2 allocation variance due to fingerprint ranges
* HSDir v2 bias due to descriptor upload times in the first and last hour
* HSDir v3 allocation variance due to fingerprint ranges
  (this requires relay ed25519 keys, which are not in the consensus)
* overlapping HSDir descriptor replicas
* one descriptor per client for services using stealth authentication
* precise client consensus download delay distributions and overlap periods

For more details, see:
https://research.torproject.org/techreports/extrapolating-hidserv-stats-2015-01-31.pdf
https://trac.torproject.org/projects/tor/ticket/23367

Example execution (the '-' means download the latest consensus from Tor):

./compute_fractional_position_weights - 068308AD070849A71B8C1DB06C2509E82C40B908 11796EF96A84A328124B64383E768AFF90BA583F 11EAB5C9137906EF7E6A32365C4B37613698E647 1A4488A367D89D0EFDA88116059FEBCACF0F508A 1A58D4BF5B4A0AF0378F650D11A6569685C35C1D 363F42695F2DD825DA5A4E6ABF3FBDFCFD1E9AE2 3887BA09C064062B711125009404B372A90BF190 493CD90F239AE608D9C046C543C59ABB9815B4DB 87AA996EFB625724F8932EF789C761E33A66A83A A2D885A9B6F4D310372EA44FC0753F45CE44D1F7 B215FA3E0C37E71FF4330EA0A7D5F75D9BD2F2BE B6718125C43ECA2E5011B3C681BB6638617A9686 BA24CD0E76682C5AAFC09CC05476B94653699A39 C127882E54F77884F8D2764CB9744B1F2C94654B C6B3546CC6BCCB649FEC82D348D464554BC6323D CE46351D06E89C0047C34AF2CED26C441B57FDF0 DE684E6C6B7773B8BE74B4D941E4178988E15E26 F6D42724B636FDF05B0EAEBE5E830C586DCFD114 0DA9BD201766EDB19F57F49F1A013A8A5432C008 12B80ABF019354A9D25EE8BE85EB3C0AD8F7DFC1 890E2EA65455FBF0FAAB4159FAC4412BDCB24295 C170AE5A886C5A09D6D1CF5CF284653632EEF25D D52CD431CEF28E01B11F545A84347EE45524BCA7 EE21F83AB6F76E3B3FFCBA5C2496F789CB84E7C6 A5945077E0D35729F8E2920A54BE12A0058B403E D53793315E290D250E9AFC431A4C9068A1E53C98

Tests:

No fingerprints:
./compute_fractional_position_weights -

All fingerprints
./compute_fractional_position_weights - -
'''

# 3 is the default number of intro points per service
# TODO: work out the weighted mean of the number of intro points per service,
#       including services with stealth client auth
INTRO_ESTABLISH_PER_SERVICE = 3.0

# 3 and 2 are the hard-coded (v2) or default consensus parameter (v3) values
HSDIR_SPREAD = 3.0
HSDIR_REPLICA = 2.0

# The entire hash ring of v2 HSDirs will see each onion address stored 6 times
# per service upload
HSDIR_V2_ONION_ADDRESS_STORE_PER_SERVICE = HSDIR_SPREAD * HSDIR_REPLICA

# The entire hash ring of v3 HSDirs will see each descriptor id stored 3 times
# per service upload
HSDIR_V3_DESCRIPTOR_ID_STORE_PER_SERVICE = HSDIR_SPREAD

# The entire hash ring of v3 HSDirs will see each descriptor id fetched
# 0.5 times per service access
HSDIR_V3_DESCRIPTOR_ID_FETCH_PER_SERVICE = 1.0 / HSDIR_REPLICA

# v2 hidden services publish two descriptors whenever they publish in the last
# hour of each period. Periods are offset throughout each day, using the first
# byte of the service's address
HSDIR_V2_STORE_OVERLAP_FRACTION = 1.0 + 1.0/24.0

def hsdir_v2_descriptor_store_overlap():
    '''
    Returns the v2 HSDir overlap proportion.
    '''
    # v2 overlaps are evenly distributed
    return HSDIR_V2_STORE_OVERLAP_FRACTION

# v3 hidden services publish a new descriptor every 24 hours. Periods start
# when the service downloads a consensus with a new SRV, and finish 36 hours
# later.
HSDIR_V3_STORE_OVERLAP_FRACTION = 1.0 + 12.0/24.0

# Average client consensus download delay, based on 1-3 hour delay
# This is approximate: a more precise figure can be calculated from:
# https://gitweb.torproject.org/torspec.git/tree/dir-spec.txt#n3345
CLIENT_CONSENSUS_DELAY_TIMEDELTA = datetime.timedelta(hours=2)

# v3 overlaps occur in from 00:00 to 12:00 UTC
# https://gitweb.torproject.org/torspec.git/tree/proposals/224-rend-spec-ng.txt#n757
HSDIR_V3_STORE_OVERLAP_START_TIME = datetime.time(hour=00)
HSDIR_V3_STORE_OVERLAP_END_TIME   = datetime.time(hour=12)

def hsdir_v3_descriptor_store_overlap(valid_after):
    '''
    Returns the v3 HSDir overlap proportion for valid_after.
    '''
    assert valid_after is not None
    valid_after -= CLIENT_CONSENSUS_DELAY_TIMEDELTA
    if (valid_after.time() > HSDIR_V3_STORE_OVERLAP_START_TIME and
        valid_after.time() <= HSDIR_V3_STORE_OVERLAP_END_TIME):
        return HSDIR_V3_STORE_OVERLAP_FRACTION
    else:
        return 1.0

ALL_FINGERPRINTS = ['-']

def main():
    print "running weights privcount version {}".format(get_privcount_version())

    args = get_args()

    cons_desc = "consensuses '{}'".format(args.consensus)
    if args.consensus == '-':
        cons_desc = "latest consensus ('-')"

    fp_desc = "fingerprints '{}'".format(args.fingerprints)
    if len(args.fingerprints) == 0:
        fp_desc = "no fingerprints (empty list)"
    elif args.fingerprints == ALL_FINGERPRINTS:
        fp_desc = "all fingerprints ('-')"

    print "using {} and {}".format(cons_desc, fp_desc)

    if args.consensus == '-':
        args.consensus = fetch_consensus()

    expanded_path = os.path.abspath(os.path.expanduser(args.consensus))
    assert os.path.exists(expanded_path)

    consensus_paths = []
    if os.path.isdir(expanded_path):
        for filename in os.listdir(expanded_path):
            if filename.endswith("consensus"):
                consensus_paths.append(os.path.join(expanded_path, filename))
        assert len(consensus_paths) > 0, "consensus file names must end with 'consensus'"
    else:
        consensus_paths.append(expanded_path)

    # Use all fingerprints for testing purposes
    if args.fingerprints == ALL_FINGERPRINTS:
        fps = None
    else:
        fps = [fp_str.strip('$') for fp_str in args.fingerprints]
    work_items = [[path, fps] for path in consensus_paths]
    results = []
    if args.use_process_pool:
        p = Pool(cpu_count())
        try:
            results = do_map(p, work_items)
        except KeyboardInterrupt:
            print >> sys.stderr, "interrupted, terminating process pool"
            p.terminate()
            p.join()
            sys.exit(1)
    else:
        for params in work_items:
            result = process_consensus(params)
            results.append(result)

    guard_fracs, middle_fracs, intro_fracs, exit_fracs, hsdir2_fracs, hsdir2_svc_fracs, hsdir3_fracs, hsdir3_svc_fracs = do_reduce(results)
    assert len(guard_fracs) > 0

    # the rend frac is the same as the middle frac
    rend_fracs = middle_fracs

    print "{:.15f} : guard use mean".format(mean(guard_fracs))
    print "{:.15f} : middle use mean".format(mean(middle_fracs))
    print "{:.15f} : exit use mean".format(mean(exit_fracs))
    print "{:.15f} : hsdir2 relay fraction mean".format(mean(hsdir2_fracs))
    print "{:.15f} : hsdir2 service onion address mean (6 stores per onion address, 1/24 overlap)".format(mean(hsdir2_svc_fracs)*HSDIR_V2_ONION_ADDRESS_STORE_PER_SERVICE)
    print "{:.15f} : hsdir2 client onion address mean (1 fetch per onion address)".format(mean(hsdir2_fracs))
    print "{:.15f} : hsdir3 relay fraction mean".format(mean(hsdir3_fracs))
    print "{:.15f} : hsdir3 service descriptor id mean (3 stores per descriptor id, per onion address, 00:00 - 12:00 overlap)".format(mean(hsdir3_svc_fracs)*HSDIR_V3_DESCRIPTOR_ID_STORE_PER_SERVICE)
    print "{:.15f} : hsdir3 client descriptor id mean (0.5 fetches per descriptor id, per onion address)".format(mean(hsdir3_fracs)*HSDIR_V3_DESCRIPTOR_ID_FETCH_PER_SERVICE)
    print "{:.15f} : intro2,3 service establish mean (default 3 intro points per onion address, max 10)".format(mean(intro_fracs)*INTRO_ESTABLISH_PER_SERVICE)
    print "{:.15f} : intro2,3 client introduce mean (1 introduce per onion address)".format(mean(intro_fracs))
    print "{:.15f} : rend2,3 use mean".format(mean(rend_fracs))

def fetch_consensus():
    downloader = DescriptorDownloader()
    consensus = downloader.get_consensus(document_handler = DocumentHandler.DOCUMENT).run()[0]

    time_label = str(consensus.valid_after).replace(':', '-').replace(' ', '-')
    file_path = "{}-consensus".format(time_label)

    if not os.path.exists(file_path):
        with open(file_path, 'w') as descriptor_file:
          descriptor_file.write("@type network-status-consensus-3 1.0\n" + str(consensus))

    return file_path

def do_map(pool, work_items):
    async_result = pool.map_async(process_consensus, work_items)
    while not async_result.ready():
        async_result.wait(1)
    return async_result.get()

# this func is run by helper processes in process pool
def process_consensus(params):
    consensus_path, prints = params[0], params[1]
    guard_frac, middle_frac, intro_frac, exit_frac, hsdir2_frac, hsdir2_svc_frac, hsdir3_frac, hsdir3_svc_frac = get_fractional_weights(consensus_path, prints)
    return [guard_frac, middle_frac, intro_frac, exit_frac, hsdir2_frac, hsdir2_svc_frac, hsdir3_frac, hsdir3_svc_frac]

def do_reduce(async_results):
    guard_fracs, middle_fracs, intro_fracs, exit_fracs, hsdir2_fracs, hsdir2_svc_fracs, hsdir3_fracs, hsdir3_svc_fracs = [], [], [], [], [], [], [], []
    for result in async_results:
        if result is None: continue
        guard_frac, middle_frac, intro_frac, exit_frac, hsdir2_frac, hsdir2_svc_frac, hsdir3_frac, hsdir3_svc_frac = result[0], result[1], result[2], result[3], result[4], result[5], result[6], result[7]
        guard_fracs.append(guard_frac)
        middle_fracs.append(middle_frac)
        intro_fracs.append(intro_frac)
        exit_fracs.append(exit_frac)
        hsdir2_fracs.append(hsdir2_frac)
        hsdir2_svc_fracs.append(hsdir2_svc_frac)
        hsdir3_fracs.append(hsdir3_frac)
        hsdir3_svc_fracs.append(hsdir3_svc_frac)
    return guard_fracs, middle_fracs, intro_fracs, exit_fracs, hsdir2_fracs, hsdir2_svc_fracs, hsdir3_fracs, hsdir3_svc_fracs

def safe_d(dividend, divisor):
    dividend = float(dividend)
    divisor = float(divisor)
    if divisor == 0.0:
        return 0.0
    else:
        return dividend/divisor

def get_fractional_weights(consensus_path, my_fingerprints):
    # returns a tuple with guard, middle, intro, exit, hsdir2 and hsdir3 fractions
    # for my_fingerprints. If my_fingerprints is None, uses all fingerprints
    # in the consensus. (This is used for testing.)
    # the rend fraction is the same as the middle fraction
    net_status = next(parse_file(consensus_path, document_handler='DOCUMENT', validate=False))
    bw_weight_scale = net_status.params['bwweightscale'] if 'bwweightscale' in net_status.params else 1.0

    my_guard, total_guard, my_middle, total_middle, my_intro, total_intro, my_exit, total_exit = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0
    # this is the integer number of HSDirs (they don't use bandwidth weights)
    my_hsdir2, total_hsdir2, my_hsdir3, total_hsdir3 = 0.0, 0.0, 0.0, 0.0

    if my_fingerprints is not None:
        for fingerprint in sorted(my_fingerprints):
            if fingerprint not in net_status.routers.keys():
                print "{} is not in consensus '{}'".format(fingerprint,
                                                           consensus_path)

    for (fingerprint, router_entry) in net_status.routers.items():
        #print fingerprint
        (guard_weighted_bw, middle_weighted_bw, intro_weighted_bw, exit_weighted_bw, hsdir2_count, hsdir3_count) = get_weighted_bandwidths(router_entry, net_status.bandwidth_weights, bw_weight_scale)
        total_guard += guard_weighted_bw
        total_middle += middle_weighted_bw
        total_intro += intro_weighted_bw
        total_exit += exit_weighted_bw
        total_hsdir2 += hsdir2_count
        total_hsdir3 += hsdir3_count
        if my_fingerprints is None or fingerprint in my_fingerprints:
            my_guard += guard_weighted_bw
            my_middle += middle_weighted_bw
            my_intro += intro_weighted_bw
            my_exit += exit_weighted_bw
            my_hsdir2 += hsdir2_count
            my_hsdir3 += hsdir3_count

    my_hsdir2_svc = my_hsdir2*hsdir_v2_descriptor_store_overlap()
    my_hsdir3_svc = my_hsdir3*hsdir_v3_descriptor_store_overlap(
                                                       net_status.valid_after)

    return safe_d(my_guard, total_guard), safe_d(my_middle, total_middle), safe_d(my_intro, total_intro), safe_d(my_exit, total_exit), safe_d(my_hsdir2, total_hsdir2), safe_d(my_hsdir2_svc, total_hsdir2), safe_d(my_hsdir3, total_hsdir3), safe_d(my_hsdir3_svc, total_hsdir3)

def get_weighted_bandwidths(router_entry, bw_weights, bw_weight_scale):
    # example bw_weights: {u'Web': 10000, u'Wdb': 10000, u'Weg': 10000, u'Wee': 10000, u'Wed': 10000, u'Wgd': 0, u'Wgb': 10000, u'Wgg': 5920, u'Wem': 10000, u'Wbg': 4080, u'Wbd': 0, u'Wbe': 0, u'Wmm': 10000, u'Wmb': 10000, u'Wgm': 5920, u'Wbm': 10000, u'Wmg': 4080, u'Wme': 0, u'Wmd': 0}
    # returns a tuple with guard, middle, intro, and exit weighted bandwidth, and hsdir2 and hsdir3 counts
    # the rend bandwidth is the same as the middle bandwidth
    guard_weighted_bw, middle_weighted_bw, intro_weighted_bw, exit_weighted_bw = 0.0, 0.0, 0.0, 0.0
    # this is the integer number of HSDirs (they don't use bandwidth weights)
    hsdir2_count, hsdir3_count = 0.0, 0.0

    bw = float(router_entry.bandwidth)
    version = router_entry.version
    protocols = router_entry.protocols

    if Flag.GUARD in router_entry.flags and Flag.FAST in router_entry.flags and Flag.STABLE in router_entry.flags:
        guard_weight = safe_d(get_bw_weight(router_entry.flags, 'g', bw_weights), bw_weight_scale)
        guard_weighted_bw = bw * guard_weight

    middle_weight = safe_d(get_bw_weight(router_entry.flags, 'm', bw_weights), bw_weight_scale)
    middle_weighted_bw = bw * middle_weight

    intro_weight = safe_d(get_bw_weight(router_entry.flags, 'i', bw_weights), bw_weight_scale)
    intro_weighted_bw = bw * intro_weight

    if 'BadExit' not in router_entry.flags:
        if router_entry.exit_policy.is_exiting_allowed():
            exit_weight = safe_d(get_bw_weight(router_entry.flags, 'e', bw_weights), bw_weight_scale)
            exit_weighted_bw = bw * exit_weight

    hsdir2_count = float(get_bw_weight(router_entry.flags, 'h2', None))
    hsdir3_count = float(get_bw_weight(router_entry.flags, 'h3', None,
                                       version=version, protocols=protocols))

    return guard_weighted_bw, middle_weighted_bw, intro_weighted_bw, exit_weighted_bw, hsdir2_count, hsdir3_count

PROTOVER_HSDIR_V3 = 2

# from torps
def get_bw_weight(flags, position, bw_weights, version=None, protocols=None):
    """Returns weight to apply to relay's bandwidth for given position, or for
        HSDirs, returns 1.0 when a relay has the flag, and 0.0 when it does not
        (version and protocols are used to check if a relay supports HSDir v3)
        flags: list of Flag values for relay from a consensus
        position: position for which to find selection weight,
             one of 'g' for guard, 'm' for middle, 'e' for exit,
             'h{2,3}' for HSDir v2 and v3, and 'i' for intro
             (the rend weight is the same as the middle weight)
        bw_weights: bandwidth_weights from NetworkStatusDocumentV3 consensus,
             or None for HSDirs
    """

    if (position == 'g'):
        if (Flag.GUARD in flags) and (Flag.EXIT in flags):
            return bw_weights['Wgd']
        elif (Flag.GUARD in flags):
            return bw_weights['Wgg']
        elif (Flag.EXIT not in flags):
            return bw_weights['Wgm']
        else:
            # exit-flagged nodes without guard flag never serve in guard position
            #raise ValueError('Wge weight does not exist.')
            return 0
    elif (position == 'm' or position == 'i'):
        # intro points must have the Stable flag
        if (position == 'i' and not Flag.STABLE in flags):
            return 0.0
        elif (Flag.GUARD in flags) and (Flag.EXIT in flags):
            return bw_weights['Wmd']
        elif (Flag.GUARD in flags):
            return bw_weights['Wmg']
        elif (Flag.EXIT in flags):
            return bw_weights['Wme']
        else:
            return bw_weights['Wmm']
    elif (position == 'e'):
        if (Flag.GUARD in flags) and (Flag.EXIT in flags):
            return bw_weights['Wed']
        elif (Flag.GUARD in flags):
            return bw_weights['Weg']
        elif (Flag.EXIT in flags):
            return bw_weights['Wee']
        else:
            return bw_weights['Wem']
    elif (position == 'h2'):
        if (Flag.HSDIR in flags):
            return 1.0
        else:
            return 0.0
    elif (position == 'h3'):
        # There is no HSDir3 flag. Instead, HSDir v3 must have the HSDir flag,
        # the HSDir protocol version 2, and a tor version >= 0.3.0.8.
        # https://trac.torproject.org/projects/tor/ticket/23340
        if (Flag.HSDIR in flags):
            if (version < Version('0.3.0.8')):
                return 0.0
            elif (protocols is not None and
                  PROTOVER_HSDIR_V3 in protocols.get('HSDir',[])):
                return 1.0
            else:
                return 0.0
        else:
            return 0.0
    else:
        raise ValueError('get_weight does not support position {0}.'.format(
            position))

class CustomHelpFormatter(ArgumentDefaultsHelpFormatter):
    # adds the 'RawDescriptionHelpFormatter' to the ArgsDefault one
    def _fill_text(self, text, width, indent):
        return ''.join([indent + line for line in text.splitlines(True)])

def get_args():
    parser = ArgumentParser(
            description='Compute weighted fractional position bandwidths for set of relays',
            formatter_class=CustomHelpFormatter)

    parser.add_argument('consensus', help="Path to a consensus file or a directory containing multiple consensus files, or '-' to download and use the latest Tor consensus", metavar="PATH")
    parser.add_argument('fingerprints', help="Fingerprints of 0 or more relays to include in reported fractions, or '-' to include all relays", metavar="FP", nargs='*')
    parser.add_argument('-m', action='store_true', dest="use_process_pool", help="Run with a {} process pool".format(cpu_count()))

    args = parser.parse_args()
    return args

if __name__ == "__main__":
    sys.exit(main())
